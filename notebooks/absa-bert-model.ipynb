{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2dda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking code from\n",
    "# https://github.com/jowagner/CA4023-NLP/blob/main/notebooks/sentiment-bert.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba763b",
   "metadata": {},
   "source": [
    "## 1.1 BERT Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1491d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 10\n",
      "Accumulating gradients of 4 batches\n"
     ]
    }
   ],
   "source": [
    "model_size          = 'base'  # choose between 'tiny', 'base' and 'large'\n",
    "max_sequence_length = 256\n",
    "batch_size          = 10\n",
    "\n",
    "# compensate for small batch size with batch accumulation if needed\n",
    "accumulate_grad_batches = 1\n",
    "while batch_size * accumulate_grad_batches < 32:\n",
    "    # accumulated batch size too small\n",
    "    # --> accumulate more batches\n",
    "    accumulate_grad_batches += 1\n",
    "\n",
    "print('Batch size:', batch_size)\n",
    "if accumulate_grad_batches > 1:\n",
    "    print('Accumulating gradients of %d batches' %accumulate_grad_batches)\n",
    "    \n",
    "size2name = {\n",
    "    'tiny':  'distilbert-base-uncased',\n",
    "    'base':  'bert-base-uncased',\n",
    "    'large': 'bert-large-uncased',\n",
    "}\n",
    "\n",
    "model_name = size2name[model_size]\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokeniser = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25048744",
   "metadata": {},
   "source": [
    "## 1.2 Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050dedf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data/ABSA16_Laptops_Train_SB1_v2.xml\n",
      "Using data/ABSA16_Restaurants_Train_SB1_v2.xml\n"
     ]
    }
   ],
   "source": [
    "domains = ['laptop', 'restaurant']\n",
    "\n",
    "train_dev_split = (90, 10)\n",
    "\n",
    "data_prefix = 'data/'\n",
    "\n",
    "filenames = {\n",
    "    'laptop':     'ABSA16_Laptops_Train_SB1_v2.xml',\n",
    "    'restaurant': 'ABSA16_Restaurants_Train_SB1_v2.xml',\n",
    "}\n",
    "\n",
    "for domain in domains:\n",
    "    filename = data_prefix + filenames[domain]\n",
    "    print('Using', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966290b",
   "metadata": {},
   "source": [
    "## 1.3 Question Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860c51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_question_first = True  # whether to put question into seq A or B\n",
    "\n",
    "templates = [\n",
    "    \n",
    "    # Hoang et al. (2019)\n",
    "    {   'question': '%(entity_type)s, %(attribute_label)s',\n",
    "        'label':    '%(polarity)s',\n",
    "    },\n",
    "    \n",
    "    # Sun et al. (2019) format 1\n",
    "    {   'question': '%(entity_type)s - %(attribute_label)s',\n",
    "        'label':    '%(polarity)s',\n",
    "    },\n",
    "    \n",
    "    # Sun et al. (2019) format 2\n",
    "    {    'question': 'What do you think of the %(attribute_label)s of %(entity_type)s?',\n",
    "         'label':    '%(polarity)s',\n",
    "    },\n",
    "    \n",
    "    # Sun et al. (2019) format 3\n",
    "    {    'question': 'The polarity of the aspect %(attribute_label)s of %(entity_type)s is %(candidate_polarity)s.',\n",
    "         'label':    '%(yesno)s',\n",
    "    },\n",
    "    \n",
    "    # Sun et al. (2019) format 4\n",
    "    {   'question': '%(entity_type)s - %(attribute_label)s - %(candidate_polarity)s',\n",
    "        'label':    '%(yesno)s',\n",
    "    },\n",
    "    \n",
    "    # Variant 1\n",
    "    {    'question': 'In terms of %(attribute_label)s, what do you think of %(entity_type)s?',\n",
    "         'label':    '%(polarity)s',\n",
    "    },\n",
    "    \n",
    "    # Variant 2\n",
    "    {    'question': 'What polarity has the sentiment towards the %(attribute_label)s of %(entity_type)s in the following rewview?',\n",
    "         'label':    '%(polarity)s',\n",
    "    },\n",
    "    \n",
    "    # Variant 3\n",
    "    {    'question': 'Do you agree that the sentiment towards the aspect %(attribute_label)s of %(entity_type)s in the following review is %(candidate_polarity)s?',\n",
    "         'label':    '%(yesno)s',\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "# TODO: add variants with entity type and attribute label not in ALLCAPS and\n",
    "#       with _ between words (requires additional code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78784a7",
   "metadata": {},
   "source": [
    "## 2.1 Get Data Instances from XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849419f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed entity types: ['AMBIENCE', 'BATTERY', 'COMPANY', 'CPU', 'DISPLAY', 'DRINKS', 'FANS_COOLING', 'FOOD', 'GRAPHICS', 'HARDWARE', 'HARD_DISC', 'KEYBOARD', 'LAPTOP', 'LOCATION', 'MEMORY', 'MOTHERBOARD', 'MOUSE', 'MULTIMEDIA_DEVICES', 'OPTICAL_DRIVES', 'OS', 'PORTS', 'POWER_SUPPLY', 'RESTAURANT', 'SERVICE', 'SHIPPING', 'SOFTWARE', 'SUPPORT', 'WARRANTY']\n",
      "\n",
      "observed attribute labels: ['CONNECTIVITY', 'DESIGN_FEATURES', 'GENERAL', 'MISCELLANEOUS', 'OPERATION_PERFORMANCE', 'PORTABILITY', 'PRICE', 'PRICES', 'QUALITY', 'STYLE_OPTIONS', 'USABILITY']\n",
      "\n",
      "observed polarities: ['negative', 'neutral', 'positive']\n",
      "\n",
      "number of unique targets: 721\n"
     ]
    }
   ],
   "source": [
    "# mostly implemented from scratch, some inspiration from\n",
    "# https://opengogs.adaptcentre.ie/rszk/sea/src/master/lib/semeval_absa.py\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "observed_entity_types = set()\n",
    "observed_attribute_labels = set()\n",
    "observed_polarities = set()\n",
    "observed_targets = set()\n",
    "\n",
    "def get_dataset(filename):\n",
    "    global observed_entity_types\n",
    "    global observed_attribute_labels\n",
    "    global observed_polarities\n",
    "    global observed_targets\n",
    "    xmltree = ElementTree.parse(filename)\n",
    "    xmlroot = xmltree.getroot()\n",
    "    dataset = []\n",
    "    for sentence in xmlroot.iter('sentence'):\n",
    "        sent_id = sentence.get('id')\n",
    "        # get content inside the first <text>...</text> sub-element\n",
    "        text = sentence.findtext('text').strip()\n",
    "        #print(sent_id, text)\n",
    "        for opinion in sentence.iter('Opinion'):\n",
    "            opin_cat = opinion.get('category')\n",
    "            entity_type, attribute_label = opin_cat.split('#')\n",
    "            polarity = opinion.get('polarity')\n",
    "            target = opinion.get('target')\n",
    "            try:\n",
    "                span = (int(opinion.get('from')), int(opinion.get('to')))\n",
    "            except TypeError:\n",
    "                # at least one of 'from' or 'to' is missing\n",
    "                span = (0, 0)\n",
    "            if target == 'NULL':\n",
    "                target = None\n",
    "            # add to dataset\n",
    "            dataset.append((\n",
    "                sent_id, text,\n",
    "                entity_type, attribute_label,\n",
    "                target, span,\n",
    "                polarity\n",
    "            ))\n",
    "            # update vocabularies\n",
    "            observed_entity_types.add(entity_type)\n",
    "            observed_attribute_labels.add(attribute_label)\n",
    "            observed_polarities.add(polarity)\n",
    "            if target:\n",
    "                observed_targets.add(target)\n",
    "    return dataset\n",
    "\n",
    "datasets = []\n",
    "for domain in domains:\n",
    "    filename = data_prefix + filenames[domain]\n",
    "    datasets.append((domain, get_dataset(filename)))\n",
    "    \n",
    "print('observed entity types:',     sorted(observed_entity_types))\n",
    "print('\\nobserved attribute labels:', sorted(observed_attribute_labels))\n",
    "print('\\nobserved polarities:',       sorted(observed_polarities))\n",
    "print('\\nnumber of unique targets:',  len(observed_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f083d49",
   "metadata": {},
   "source": [
    "## 2.2 PyTorch DataLoader\n",
    "\n",
    "To use the PyTorch Lighting framwork, we need to distinguish 3 types of objects handling our data:\n",
    "\n",
    "### Dataset\n",
    "\n",
    "PyTorch Dataset objects provide access to a data set and behave like a list of dictionaries, one dictionary for each data instance (training or test item). The framework does not prescribe what the dictionaries look like, i.e. you can choose the keys. The length of the list determines the number of training instances in each epoch, unless the DataLoader (below) is extended to filter or augment the data. The standard way to augment data is to keep the number of instances identical to the number of raw instances and to apply a different or random transformation in each call of `__getitem__()`.\n",
    "\n",
    "### DataLoader\n",
    "\n",
    "PyTorch DataLoader objects shuffle data provided by a Dataset object and create batches of data.\n",
    "\n",
    "### LightningDataModule\n",
    "\n",
    "LightningDataModule objects create 3 DataLoader objects, one each for training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9a90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic usage of pytorch and lightning from\n",
    "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "# and\n",
    "# https://github.com/ricardorei/lightning-text-classification/blob/master/classifier.py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "\n",
    "class ABSA_Dataset_part_1(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        raw_data,\n",
    "        put_question_first = True,\n",
    "        question_prefix = None,\n",
    "        template_index = -1,    # -1 = pick random template\n",
    "        info = None,            # additional info to keep with each instance\n",
    "    ):\n",
    "        self.raw_data            = raw_data\n",
    "        self.put_question_first  = put_question_first\n",
    "        self.question_prefix     = question_prefix\n",
    "        self.template_index      = template_index\n",
    "        self.info                = info\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ''' get one instance of the dataset as a custom dictionary\n",
    "        '''\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            assert isinstance(idx, int)\n",
    "        sent_id, text, \\\n",
    "            entity_type, attribute_label, \\\n",
    "            target, span, \\\n",
    "            polarity = self.raw_data[idx]\n",
    "        question, label = self.pick_question(entity_type, attribute_label, polarity)\n",
    "        if self.question_prefix:\n",
    "            question = self.question_prefix + ' ' + question\n",
    "        # TODO: support adding context (previous sentences) to text\n",
    "        retval = {}\n",
    "        if self.put_question_first:\n",
    "            retval['seq_A'] = question\n",
    "            retval['seq_B'] = text\n",
    "        else:\n",
    "            retval['seq_A'] = text\n",
    "            retval['seq_B'] = question\n",
    "        retval['label'] = label\n",
    "        retval['info']  = self.info\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f674226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ABSA_Dataset(ABSA_Dataset_part_1):\n",
    "                   \n",
    "    def pick_question(self, entity_type, attribute_label, polarity):\n",
    "        global templates\n",
    "        global observed_polarities\n",
    "        if self.template_index < 0:\n",
    "            template = random.choice(templates)\n",
    "        else:\n",
    "            template = templates[self.template_index]\n",
    "        candidate_polarity = random.choice(list(observed_polarities))\n",
    "        if candidate_polarity == polarity:\n",
    "            yesno = 'yes'\n",
    "        else:\n",
    "            yesno = 'no'\n",
    "        question = template['question'] %locals()\n",
    "        label    = template['label']    %locals()\n",
    "        return (question, label)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c3a62",
   "metadata": {},
   "source": [
    "## 2.3 Training-Dev Split\n",
    "The SemEval ABSA dataset comes without a dev set. We need a dev set to decide how long to train, to select other parameters and to select a good run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76188f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop 2909\n",
      "restaurant 2507\n",
      "Total size: 5416\n",
      "('positive', 'laptop'): split 1473 (90.0%) to 164 (10.0%)\n",
      "('negative', 'laptop'): split 975 (89.9%) to 109 (10.1%)\n",
      "('neutral', 'laptop'): split 169 (89.9%) to 19 (10.1%)\n",
      "('negative', 'restaurant'): split 674 (90.0%) to 75 (10.0%)\n",
      "('positive', 'restaurant'): split 1491 (90.0%) to 166 (10.0%)\n",
      "('neutral', 'restaurant'): split 90 (89.1%) to 11 (10.9%)\n",
      "Training data size: 4872\n",
      "Development data size: 544\n"
     ]
    }
   ],
   "source": [
    "# concatenate domains\n",
    "\n",
    "tr_dataset_objects = []\n",
    "\n",
    "for domain, dataset in datasets:\n",
    "    print(domain, len(dataset))\n",
    "    tr_dataset_objects.append(ABSA_Dataset(\n",
    "        dataset,\n",
    "        put_question_first = put_question_first,\n",
    "        question_prefix = domain + ':',\n",
    "        template_index  = 0,   # a template that keeps the original 3-value polarity\n",
    "        info = domain\n",
    "    ))\n",
    "\n",
    "tr_dataset = torch.utils.data.ConcatDataset(tr_dataset_objects)\n",
    "n = len(tr_dataset)\n",
    "print('Total size:', n)\n",
    "\n",
    "# how many instances are there for each label?\n",
    "\n",
    "group2indices = {}\n",
    "for index in range(n):\n",
    "    label = tr_dataset[index]['label']\n",
    "    domain = tr_dataset[index]['info']\n",
    "    group = (label, domain)\n",
    "    if not group in group2indices:\n",
    "        group2indices[group] = []\n",
    "    group2indices[group].append(index)\n",
    "\n",
    "# create stratified sample\n",
    "    \n",
    "rel_train_size, rel_dev_size = train_dev_split\n",
    "rel_total = rel_train_size + rel_dev_size\n",
    "\n",
    "tr_indices = []\n",
    "dev_indices = []\n",
    "\n",
    "for group in group2indices:\n",
    "    indices = group2indices[group]\n",
    "    n = len(indices)\n",
    "    select = (n * rel_train_size) // rel_total\n",
    "    remaining = n - select\n",
    "    print('%r: split %d (%.1f%%) to %d (%.1f%%)' %(\n",
    "        group, select, 100.0*select/float(n),\n",
    "        remaining, 100.0*remaining/float(n),\n",
    "    ))\n",
    "    random.shuffle(indices)\n",
    "    tr_indices += indices[:select]\n",
    "    dev_indices += indices[select:]\n",
    "    \n",
    "dev_dataset = torch.utils.data.Subset(tr_dataset, dev_indices)\n",
    "tr_dataset  = torch.utils.data.Subset(tr_dataset, tr_indices)\n",
    "\n",
    "print('Training data size:', len(tr_dataset))\n",
    "print('Development data size:', len(dev_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f85d9",
   "metadata": {},
   "source": [
    "## Appendix A: Example BERT Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a3a5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tinput:         This computer is absolutely AMAZING!!!\n",
      "\t['input_ids']: [101, 2023, 3274, 2003, 7078, 6429, 999, 999, 999, 102]\n",
      "\ttokens:        ['[CLS]', 'this', 'computer', 'is', 'absolutely', 'amazing', '!', '!', '!', '[SEP]']\n",
      "\n",
      "1 \tinput:         and plenty of storage with 250 gb(though I will upgrade this and the ram..)\n",
      "\t['input_ids']: [101, 1998, 7564, 1997, 5527, 2007, 5539, 16351, 1006, 2295, 1045, 2097, 12200, 2023, 1998, 1996, 8223, 1012, 1012, 1007, 102]\n",
      "\ttokens:        ['[CLS]', 'and', 'plenty', 'of', 'storage', 'with', '250', 'gb', '(', 'though', 'i', 'will', 'upgrade', 'this', 'and', 'the', 'ram', '.', '.', ')', '[SEP]']\n",
      "\n",
      "2 \tinput:         GET THIS COMPUTER FOR PORTABILITY AND FAST PROCESSING!!!\n",
      "\t['input_ids']: [101, 2131, 2023, 3274, 2005, 3417, 8010, 1998, 3435, 6364, 999, 999, 999, 102]\n",
      "\ttokens:        ['[CLS]', 'get', 'this', 'computer', 'for', 'port', '##ability', 'and', 'fast', 'processing', '!', '!', '!', '[SEP]']\n",
      "\n",
      "3 \tinput:         without a big ol' clunky machine in my backpack, I feel like I can do programming homework anywhere.\n",
      "\t['input_ids']: [101, 2302, 1037, 2502, 19330, 1005, 18856, 16814, 2100, 3698, 1999, 2026, 13383, 1010, 1045, 2514, 2066, 1045, 2064, 2079, 4730, 19453, 5973, 1012, 102]\n",
      "\ttokens:        ['[CLS]', 'without', 'a', 'big', 'ol', \"'\", 'cl', '##unk', '##y', 'machine', 'in', 'my', 'backpack', ',', 'i', 'feel', 'like', 'i', 'can', 'do', 'programming', 'homework', 'anywhere', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "example_batch = []\n",
    "for domain, dataset in datasets:\n",
    "    if domain == 'laptop':\n",
    "        for i in (0, 4, 8, 18):  # select a few interesting instances\n",
    "            example_batch.append(dataset[i][1])   \n",
    "\n",
    "tokenised_text = tokeniser(\n",
    "    example_batch,\n",
    "    is_split_into_words = False,\n",
    ")\n",
    "\n",
    "for i, token_ids in enumerate(tokenised_text['input_ids']):\n",
    "    if i: print()\n",
    "    print(i, '\\tinput:        ', example_batch[i])\n",
    "    print(   \"\\t['input_ids']:\", token_ids)\n",
    "    print(   '\\ttokens:       ', tokeniser.convert_ids_to_tokens(token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01347f",
   "metadata": {},
   "source": [
    "## Appendix B: Sequence Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52b55d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop\n",
      "LengthBin\t    negative\t     neutral\t    positive\t       Total\t  Positivity\n",
      "   0-   9\t         123\t          20\t         279\t         422\t        66%\n",
      "  10-  19\t         484\t          75\t         744\t        1303\t        57%\n",
      "  20-  29\t         303\t          59\t         428\t         790\t        54%\n",
      "  30-  39\t         102\t          17\t         125\t         244\t        51%\n",
      "  40-  49\t          47\t          15\t          38\t         100\t        38%\n",
      "  50-  59\t          11\t           2\t          20\t          33\t        61%\n",
      "  60-  69\t           8\t           0\t           0\t           8\t         0%\n",
      "  70-  79\t           3\t           0\t           3\t           6\t        50%\n",
      "  80-  89\t           3\t           0\t           0\t           3\t         0%\n",
      "restaurant\n",
      "LengthBin\t    negative\t     neutral\t    positive\t       Total\t  Positivity\n",
      "   0-   9\t          74\t          13\t         276\t         363\t        76%\n",
      "  10-  19\t         300\t          52\t         724\t        1076\t        67%\n",
      "  20-  29\t         183\t          21\t         432\t         636\t        68%\n",
      "  30-  39\t         111\t          11\t         145\t         267\t        54%\n",
      "  40-  49\t          43\t           4\t          40\t          87\t        46%\n",
      "  50-  59\t          26\t           0\t          27\t          53\t        51%\n",
      "  60-  69\t           9\t           0\t           6\t          15\t        40%\n",
      "  70-  79\t           3\t           0\t           0\t           3\t         0%\n",
      "  80-  89\t           0\t           0\t           0\t           0\t        n/a\n",
      "  90-  99\t           0\t           0\t           7\t           7\t       100%\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "    \n",
    "bin_width = 10\n",
    "\n",
    "for domain, dataset in datasets:\n",
    "    print(domain)\n",
    "    distribution = defaultdict(lambda: 0)\n",
    "    dataset.append(7*[None])  # hack to simplify loop below\n",
    "    batch = []\n",
    "    labels = []\n",
    "    max_length_bin = 0\n",
    "    for _, text, _, _, _, _, label in dataset:\n",
    "        if text is not None:\n",
    "            batch.append(text)\n",
    "            labels.append(label)\n",
    "        if len(batch) == batch_size \\\n",
    "        or (text is None and len(batch) > 0):\n",
    "            tokenised_batch = tokeniser(\n",
    "                batch,\n",
    "                is_split_into_words = False,\n",
    "            )\n",
    "            for index, token_ids in enumerate(tokenised_batch['input_ids']):\n",
    "                label = labels[index]\n",
    "                length = len(token_ids)\n",
    "                length_bin = length // bin_width\n",
    "                distribution[(label,   length_bin)] += 1\n",
    "                distribution[('total', length_bin)] += 1\n",
    "                if length_bin > max_length_bin:\n",
    "                    max_length_bin = length_bin\n",
    "            batch = []\n",
    "            labels = []\n",
    "    del dataset[-1]  # remove \"end of data\" marker of hack above   \n",
    "    header = []\n",
    "    header.append('LengthBin')\n",
    "    for polarity in sorted(observed_polarities):\n",
    "        header.append('%12s' %polarity)\n",
    "    header.append('%12s' %'Total')\n",
    "    header.append('%12s' %'Positivity')\n",
    "    print('\\t'.join(header))\n",
    "    for length_bin in range(0, max_length_bin+1):\n",
    "        row = []\n",
    "        row.append('%4d-%4d' %(\n",
    "            bin_width*length_bin,\n",
    "            bin_width*(1+length_bin)-1\n",
    "        ))\n",
    "        total = 0\n",
    "        for label in sorted(observed_polarities):\n",
    "            count = distribution[(label, length_bin)]\n",
    "            row.append('%12d' %count)\n",
    "            total += count\n",
    "        row.append('%12d' %total)\n",
    "        if total:\n",
    "            row.append('%10.0f%%' %(100.0*distribution[('positive', length_bin)]/float(total)))\n",
    "        else:\n",
    "            row.append('%11s' %'n/a')\n",
    "        print('\\t'.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f75282",
   "metadata": {},
   "source": [
    "## Appendix C: Example Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5b5d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop\n",
      "0 {'seq_A': 'laptop: LAPTOP - GENERAL', 'seq_B': 'This computer is absolutely AMAZING!!!', 'label': 'positive', 'info': None}\n",
      "0 {'seq_A': 'laptop: LAPTOP, GENERAL', 'seq_B': 'This computer is absolutely AMAZING!!!', 'label': 'positive', 'info': None}\n",
      "1 {'seq_A': 'laptop: Do you agree that the sentiment towards the aspect OPERATION_PERFORMANCE of BATTERY in the following review is neutral?', 'seq_B': '10 plus hours of battery...', 'label': 'no', 'info': None}\n",
      "1 {'seq_A': 'laptop: What do you think of the OPERATION_PERFORMANCE of BATTERY?', 'seq_B': '10 plus hours of battery...', 'label': 'positive', 'info': None}\n",
      "\n",
      "restaurant\n",
      "0 {'seq_A': 'restaurant: What polarity has the sentiment towards the GENERAL of RESTAURANT in the following rewview?', 'seq_B': 'Judging from previous posts this used to be a good place, but not any longer.', 'label': 'negative', 'info': None}\n",
      "0 {'seq_A': 'restaurant: What polarity has the sentiment towards the GENERAL of RESTAURANT in the following rewview?', 'seq_B': 'Judging from previous posts this used to be a good place, but not any longer.', 'label': 'negative', 'info': None}\n",
      "1 {'seq_A': 'restaurant: Do you agree that the sentiment towards the aspect GENERAL of SERVICE in the following review is positive?', 'seq_B': 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.', 'label': 'no', 'info': None}\n",
      "1 {'seq_A': 'restaurant: Do you agree that the sentiment towards the aspect GENERAL of SERVICE in the following review is negative?', 'seq_B': 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.', 'label': 'yes', 'info': None}\n"
     ]
    }
   ],
   "source": [
    "is_first = True\n",
    "for domain, dataset in datasets:\n",
    "    if not is_first: print()\n",
    "    print(domain)\n",
    "    dataset_obj = ABSA_Dataset(\n",
    "        dataset,\n",
    "        put_question_first = put_question_first,\n",
    "        question_prefix = domain + ':',\n",
    "        template_index = -1,   # -1 = random pick\n",
    "    )\n",
    "    for i in range(2):\n",
    "        print(i, dataset_obj[i])\n",
    "        print(i, dataset_obj[i])  # repeat call doesn't give the same result with template_index = -1\n",
    "    is_first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27434d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b987f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
