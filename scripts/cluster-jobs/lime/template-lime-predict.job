#!/bin/bash

#SBATCH -p compute       # which partition to run on
#SBATCH --gres=gpu:%(gpu)s:1
#SBATCH -J lpd-%(shortname)s%(part)d%(run)d    # name for the job
#SBATCH --mem=7168
#SBATCH --cpus-per-task=4
#SBATCH --ntasks=1
#SBATCH -N 1-1
#SBATCH --exclude=g103
#SBATCH --requeue
#SBATCH --qos=preempt
%(more_sbatch)s


PRJ_DIR=${HOME}/sentiment/absa-rationale-eval
cd $PRJ_DIR
source venv-pytorch/bin/activate

SET=%(part)d
TR_TASK=%(longname)s
TR_TASK_SHORT=%(shortname)s

OUTNAME=lime-predict-%(outsuffix)s-$(scripts/get-slurm-restart-count.py 3)

for RUN in %(run)d ; do
    echo "== Set ${SET} Run $RUN =="
    date
    cd $PRJ_DIR
    MODEL_DIR=c-${TR_TASK_SHORT}-${SET}-${RUN}
    cd $MODEL_DIR
    ln -s ../data
    hostname >> ${OUTNAME}.start
    date     >> ${OUTNAME}.start
    echo $MODEL_DIR >> ${OUTNAME}.start
    echo $SLURM_JOB_ID >> ${OUTNAME}.start
    nvidia-smi         >> ${OUTNAME}.start
    touch ${OUTNAME}.start
    ../scripts/train-classifier.py  \
        --load-from best-sea.ckpt   \
        --max-MiB 4096              \
        --speed %(speed).3f         \
        --batch-size %(batchsize)d  \
        --hours %(hours).3f         \
        predict                     \
        2> ${OUTNAME}.err > ${OUTNAME}.out
    date >> ${OUTNAME}.end
    touch   ${OUTNAME}.end
    date
    echo "done"
done
